{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练深度神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization批量标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (reset_tf_graph, show_tf_graph)\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载mnist数据\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /app/machine_learning/hands-on-ml/utils.py:7: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-ab9b876b362f>:30: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-3-ab9b876b362f>:31: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45aab3ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "reset_tf_graph()\n",
    "\n",
    "n_inputs = 28*28 # minst里的图像分辨率是28*28\n",
    "n_hidden1 = 300 # 第一个隐藏层的神经元数量\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10 # 分类10个数字\n",
    "\n",
    "batch_norm_momentum = 0.9 # 标准化的偏移量\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer() # 使用HE初始化权重\n",
    "\n",
    "    my_batch_norm_layer = partial( # 类似做函数的柯里化curring, 填入部分函数值生成新的函数\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1)) # 标准化后再执行激活函数ELU - 指数线性单元\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8952\n",
      "1 Validation accuracy: 0.9202\n",
      "2 Validation accuracy: 0.9318\n",
      "3 Validation accuracy: 0.9422\n",
      "4 Validation accuracy: 0.9468\n",
      "5 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9662\n",
      "11 Validation accuracy: 0.9682\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9696\n",
      "14 Validation accuracy: 0.9706\n",
      "15 Validation accuracy: 0.9704\n",
      "16 Validation accuracy: 0.9718\n",
      "17 Validation accuracy: 0.9726\n",
      "18 Validation accuracy: 0.9738\n",
      "19 Validation accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "# 定义一个从训练集中随机挑选50个实例的方法\n",
    "def batch_generator(X, y, size):\n",
    "    rnd_idx = np.random.permutation(len(X)) # len(X)是矩阵X的第0维的长度, 生成0..len(X)的随机数\n",
    "    n_batches = len(X) // batch_size # //是整除, mod\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch # yield定义了生成器generator, 可以用next(generator)来调用, 也可以用for循环调用\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in batch_generator(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./chpt11/my_model_final.ckpt\")\n",
    "    \n",
    "file_writer = tf.summary.FileWriter(\"./chpt11/graph\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAX Norm 最大范数约束正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (reset_tf_graph, show_tf_graph)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 加载mnist数据\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/living/anaconda3/envs/dev-gpu/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/living/anaconda3/envs/dev-gpu/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa457b04b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aaa9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aaa9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aaa9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45aaa9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # there is no regularization loss term\n",
    "    return max_norm\n",
    "\n",
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\", kernel_regularizer=max_norm_reg)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\", kernel_regularizer=max_norm_reg)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义权重裁剪操作\n",
    "\n",
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)\n",
    "\n",
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9556\n",
      "1 Validation accuracy: 0.9698\n",
      "2 Validation accuracy: 0.9724\n",
      "3 Validation accuracy: 0.975\n",
      "4 Validation accuracy: 0.9752\n",
      "5 Validation accuracy: 0.9776\n",
      "6 Validation accuracy: 0.979\n",
      "7 Validation accuracy: 0.9808\n",
      "8 Validation accuracy: 0.9818\n",
      "9 Validation accuracy: 0.9814\n",
      "10 Validation accuracy: 0.9828\n",
      "11 Validation accuracy: 0.981\n",
      "12 Validation accuracy: 0.981\n",
      "13 Validation accuracy: 0.9818\n",
      "14 Validation accuracy: 0.9818\n",
      "15 Validation accuracy: 0.982\n",
      "16 Validation accuracy: 0.9824\n",
      "17 Validation accuracy: 0.983\n",
      "18 Validation accuracy: 0.9832\n",
      "19 Validation accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "# 定义一个从训练集中随机挑选50个实例的方法\n",
    "def batch_generator(X, y, size):\n",
    "    rnd_idx = np.random.permutation(len(X)) # len(X)是矩阵X的第0维的长度, 生成0..len(X)的随机数\n",
    "    n_batches = len(X) // batch_size # //是整除, mod\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch # yield定义了生成器generator, 可以用next(generator)来调用, 也可以用for循环调用\n",
    "\n",
    "with tf.Session() as sess:                                              \n",
    "    init.run()                                                          \n",
    "    for epoch in range(n_epochs):                                       \n",
    "        for X_batch, y_batch in batch_generator(X_train, y_train, batch_size): \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()                                        \n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})   \n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)                 \n",
    "\n",
    "    save_path = saver.save(sess, \"./chpt11/model/max_norm.ckpt\")\n",
    "    \n",
    "file_writer = tf.summary.FileWriter(\"./chpt11/graph/max_norm\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.深度学习。\n",
    "\n",
    "i.  建立一个 DNN,有五个隐藏层,每层 100 个神经元,使用 He 初始化和 ELU 激活函数。\n",
    "\n",
    "ii.  使用 Adam 优化和提前停止,请尝试在 MNIST 上进行训练,但只能使用数字 0 到4,因为我们将在下一个练习中在数字 5 到 9 上进行迁移学习。 您需要一个包含五个神经元的 softmax 输出层,并且一如既往地确保定期保存检查点,并保存最终模型,以便稍后再使用它。\n",
    "\n",
    "iii.  使用交叉验证调整超参数,并查看你能达到什么准确度。\n",
    "\n",
    "iv.  现在尝试添加批量标准化并比较学习曲线:它是否比以前收敛得更快? 它是否会产生更好的模型? v.  模型是否过拟合训练集? 尝试将 dropout 添加到每一层,然后重试。 它有帮助吗?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (reset_tf_graph, show_tf_graph)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载mnist数据\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取数据集中0~4的部分\n",
    "X_train_04 = X_train[y_train <= 4]\n",
    "y_train_04 = y_train[y_train <= 4]\n",
    "X_valid_04 = X_valid[y_valid <= 4]\n",
    "y_valid_04 = y_valid[y_valid <= 4]\n",
    "X_test_04 = X_test[y_test <= 4]\n",
    "y_test_04 = y_test[y_test <= 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b432e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b432e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b432e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b432e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4570a83c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4570a83c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4570a83c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4570a83c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa460309160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa460309160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa460309160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa460309160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a249e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b36208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b36208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b36208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b36208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b41fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b41fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b41fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b41fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 28*28\n",
    "n_outputs = 5\n",
    "n_hidden_neurons = 100\n",
    "n_hidden_layers = 5\n",
    "\n",
    "reset_tf_graph()\n",
    "\n",
    "# 定义输入参数\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "# 定义层\n",
    "he_init = tf.initializers.variance_scaling()\n",
    "\n",
    "def make_dnn(inputs):\n",
    "    with tf.name_scope(\"dnn\") as scope:\n",
    "        for n in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_hidden_neurons, \n",
    "                                     activation=tf.nn.elu, kernel_initializer=he_init,\n",
    "                                     name=\"hidden%d\" % (n + 1))\n",
    "        return inputs\n",
    "\n",
    "dnn_outputs = make_dnn(X)\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, \n",
    "                         kernel_initializer=he_init,\n",
    "                        name=\"logits\")\n",
    "y_probs = tf.nn.softmax(logits, name=\"y_probs\")\n",
    "\n",
    "# 定义交叉熵损失函数\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "# 定义训练操作\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  0.122529425\n",
      "0 Validation accuracy: 0.9679437\n",
      "epoch: 0, validation loss: 0.122529, best loss: 0.122529, accuracy: 96.79%\n",
      "1 loss:  0.16210127\n",
      "1 Validation accuracy: 0.9644253\n",
      "epoch: 1, validation loss: 0.162101, best loss: 0.122529, accuracy: 96.44%\n",
      "2 loss:  0.10851233\n",
      "2 Validation accuracy: 0.97380763\n",
      "epoch: 2, validation loss: 0.108512, best loss: 0.108512, accuracy: 97.38%\n",
      "3 loss:  0.08987865\n",
      "3 Validation accuracy: 0.9792807\n",
      "epoch: 3, validation loss: 0.089879, best loss: 0.089879, accuracy: 97.93%\n",
      "4 loss:  0.16509594\n",
      "4 Validation accuracy: 0.9648163\n",
      "epoch: 4, validation loss: 0.165096, best loss: 0.089879, accuracy: 96.48%\n",
      "5 loss:  0.13795923\n",
      "5 Validation accuracy: 0.9749805\n",
      "epoch: 5, validation loss: 0.137959, best loss: 0.089879, accuracy: 97.50%\n",
      "6 loss:  0.11189643\n",
      "6 Validation accuracy: 0.97537136\n",
      "epoch: 6, validation loss: 0.111896, best loss: 0.089879, accuracy: 97.54%\n",
      "7 loss:  0.13033368\n",
      "7 Validation accuracy: 0.97263485\n",
      "epoch: 7, validation loss: 0.130334, best loss: 0.089879, accuracy: 97.26%\n",
      "8 loss:  0.61058503\n",
      "8 Validation accuracy: 0.78342456\n",
      "epoch: 8, validation loss: 0.610585, best loss: 0.089879, accuracy: 78.34%\n",
      "9 loss:  0.32254657\n",
      "9 Validation accuracy: 0.9710711\n",
      "epoch: 9, validation loss: 0.322547, best loss: 0.089879, accuracy: 97.11%\n",
      "10 loss:  0.8121211\n",
      "10 Validation accuracy: 0.92220485\n",
      "epoch: 10, validation loss: 0.812121, best loss: 0.089879, accuracy: 92.22%\n",
      "11 loss:  1.3631334\n",
      "11 Validation accuracy: 0.34362784\n",
      "epoch: 11, validation loss: 1.363133, best loss: 0.089879, accuracy: 34.36%\n",
      "12 loss:  1.379614\n",
      "12 Validation accuracy: 0.38154808\n",
      "epoch: 12, validation loss: 1.379614, best loss: 0.089879, accuracy: 38.15%\n",
      "13 loss:  1.3626913\n",
      "13 Validation accuracy: 0.353792\n",
      "epoch: 13, validation loss: 1.362691, best loss: 0.089879, accuracy: 35.38%\n",
      "14 loss:  1.5563793\n",
      "14 Validation accuracy: 0.26817825\n",
      "epoch: 14, validation loss: 1.556379, best loss: 0.089879, accuracy: 26.82%\n",
      "15 loss:  1.3740369\n",
      "15 Validation accuracy: 0.38623926\n",
      "epoch: 15, validation loss: 1.374037, best loss: 0.089879, accuracy: 38.62%\n",
      "16 loss:  1.3926783\n",
      "16 Validation accuracy: 0.34128225\n",
      "epoch: 16, validation loss: 1.392678, best loss: 0.089879, accuracy: 34.13%\n",
      "17 loss:  1.3289797\n",
      "17 Validation accuracy: 0.33229086\n",
      "epoch: 17, validation loss: 1.328980, best loss: 0.089879, accuracy: 33.23%\n",
      "18 loss:  1.5473971\n",
      "18 Validation accuracy: 0.2353401\n",
      "epoch: 18, validation loss: 1.547397, best loss: 0.089879, accuracy: 23.53%\n",
      "19 loss:  1.2942728\n",
      "19 Validation accuracy: 0.34792808\n",
      "epoch: 19, validation loss: 1.294273, best loss: 0.089879, accuracy: 34.79%\n",
      "20 loss:  1.3856318\n",
      "20 Validation accuracy: 0.3639562\n",
      "epoch: 20, validation loss: 1.385632, best loss: 0.089879, accuracy: 36.40%\n",
      "21 loss:  1.4139172\n",
      "21 Validation accuracy: 0.3506646\n",
      "epoch: 21, validation loss: 1.413917, best loss: 0.089879, accuracy: 35.07%\n",
      "22 loss:  3.7077403\n",
      "22 Validation accuracy: 0.24081314\n",
      "epoch: 22, validation loss: 3.707740, best loss: 0.089879, accuracy: 24.08%\n",
      "23 loss:  1.2682308\n",
      "23 Validation accuracy: 0.37568414\n",
      "epoch: 23, validation loss: 1.268231, best loss: 0.089879, accuracy: 37.57%\n",
      "24 loss:  1.3937862\n",
      "24 Validation accuracy: 0.36786553\n",
      "Early stopping! \n",
      "WARNING:tensorflow:From /home/living/anaconda3/envs/dev-gpu/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./chpt11/model/ex8_2.ckpt\n",
      "Final test accuracy: 97.86%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "n_epochs_before_stop = 20\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "best_loss = np.infty\n",
    "\n",
    "\n",
    "# 定义一个从训练集中随机挑选50个实例的方法\n",
    "def batch_generator(X, y, size):\n",
    "    rnd_idx = np.random.permutation(len(X)) # len(X)是矩阵X的第0维的长度, 生成0..len(X)的随机数\n",
    "    n_batches = len(X) // batch_size # //是整除, mod\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch # yield定义了生成器generator, 可以用next(generator)来调用, 也可以用for循环调用\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    n_epochs_after_best = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in batch_generator(X_train_04, y_train_04, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        the_loss, acc_valid = sess.run([loss, accuracy], feed_dict={X: X_valid_04, y: y_valid_04})\n",
    "        print(epoch, \"loss: \", the_loss)\n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)\n",
    "        \n",
    "        if the_loss < best_loss:\n",
    "            best_loss = the_loss\n",
    "            n_epochs_after_best = 0\n",
    "            save_path = saver.save(sess, \"./chpt11/model/ex8_2.ckpt\")\n",
    "        else:\n",
    "            n_epochs_after_best += 1\n",
    "            if n_epochs_after_best > n_epochs_before_stop:\n",
    "                print(\"Early stopping! \")\n",
    "                break\n",
    "        print(\"epoch: {}, validation loss: {:.6f}, best loss: {:.6f}, accuracy: {:.2f}%\".format(\n",
    "            epoch, the_loss, best_loss, acc_valid * 100))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./chpt11/model/ex8_2.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test_04, y: y_test_04})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4 使用批量标准化重新定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578cccf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578cccf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578cccf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578cccf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a23d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a23d668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a23d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a23d668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a051ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a051ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a051ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45a051ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a051ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a051ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a051ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45a051ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455e3f438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455e3f438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455e3f438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455e3f438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45686fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455db9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455db9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455db9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa455db9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b43208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b43208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b43208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456b43208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 28*28\n",
    "n_outputs = 5\n",
    "n_hidden_neurons = 100\n",
    "n_hidden_layers = 5\n",
    "\n",
    "reset_tf_graph()\n",
    "\n",
    "# 定义输入参数\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder(tf.bool, name=\"training\")\n",
    "\n",
    "# 定义层\n",
    "he_init = tf.initializers.variance_scaling()\n",
    "\n",
    "def make_dnn(inputs):\n",
    "    with tf.name_scope(\"dnn\") as scope:\n",
    "        for n in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_hidden_neurons, \n",
    "                                     kernel_initializer=he_init,\n",
    "                                     name=\"hidden%d\" % (n + 1))\n",
    "            # 添加批量标准化\n",
    "            inputs = tf.nn.elu(tf.layers.batch_normalization(inputs, training=training, momentum=0.9))\n",
    "        return inputs\n",
    "\n",
    "dnn_outputs = make_dnn(X)\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, \n",
    "                         kernel_initializer=he_init,\n",
    "                        name=\"logits\")\n",
    "y_probs = tf.nn.softmax(logits, name=\"y_probs\")\n",
    "\n",
    "# 定义交叉熵损失函数\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "# 定义训练操作\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  0.07584884\n",
      "0 Validation accuracy: 0.97732604\n",
      "epoch: 0, validation loss: 0.075849, best loss: 0.075849, accuracy: 97.73%\n",
      "1 loss:  0.059287775\n",
      "1 Validation accuracy: 0.9812353\n",
      "epoch: 1, validation loss: 0.059288, best loss: 0.059288, accuracy: 98.12%\n",
      "2 loss:  0.079557754\n",
      "2 Validation accuracy: 0.97732604\n",
      "epoch: 2, validation loss: 0.079558, best loss: 0.059288, accuracy: 97.73%\n",
      "3 loss:  0.05218364\n",
      "3 Validation accuracy: 0.98553556\n",
      "epoch: 3, validation loss: 0.052184, best loss: 0.052184, accuracy: 98.55%\n",
      "4 loss:  0.04628764\n",
      "4 Validation accuracy: 0.98553556\n",
      "epoch: 4, validation loss: 0.046288, best loss: 0.046288, accuracy: 98.55%\n",
      "5 loss:  0.038808044\n",
      "5 Validation accuracy: 0.99022675\n",
      "epoch: 5, validation loss: 0.038808, best loss: 0.038808, accuracy: 99.02%\n",
      "6 loss:  0.042522825\n",
      "6 Validation accuracy: 0.9851446\n",
      "epoch: 6, validation loss: 0.042523, best loss: 0.038808, accuracy: 98.51%\n",
      "7 loss:  0.030690484\n",
      "7 Validation accuracy: 0.99022675\n",
      "epoch: 7, validation loss: 0.030690, best loss: 0.030690, accuracy: 99.02%\n",
      "8 loss:  0.04122322\n",
      "8 Validation accuracy: 0.98749024\n",
      "epoch: 8, validation loss: 0.041223, best loss: 0.030690, accuracy: 98.75%\n",
      "9 loss:  0.036540344\n",
      "9 Validation accuracy: 0.9878812\n",
      "epoch: 9, validation loss: 0.036540, best loss: 0.030690, accuracy: 98.79%\n",
      "10 loss:  0.03751555\n",
      "10 Validation accuracy: 0.988663\n",
      "epoch: 10, validation loss: 0.037516, best loss: 0.030690, accuracy: 98.87%\n",
      "11 loss:  0.043886647\n",
      "11 Validation accuracy: 0.9917905\n",
      "epoch: 11, validation loss: 0.043887, best loss: 0.030690, accuracy: 99.18%\n",
      "12 loss:  0.036841314\n",
      "12 Validation accuracy: 0.9878812\n",
      "epoch: 12, validation loss: 0.036841, best loss: 0.030690, accuracy: 98.79%\n",
      "13 loss:  0.037211176\n",
      "13 Validation accuracy: 0.9878812\n",
      "epoch: 13, validation loss: 0.037211, best loss: 0.030690, accuracy: 98.79%\n",
      "14 loss:  0.03309078\n",
      "14 Validation accuracy: 0.9913995\n",
      "epoch: 14, validation loss: 0.033091, best loss: 0.030690, accuracy: 99.14%\n",
      "15 loss:  0.03714165\n",
      "15 Validation accuracy: 0.9898358\n",
      "epoch: 15, validation loss: 0.037142, best loss: 0.030690, accuracy: 98.98%\n",
      "16 loss:  0.034091145\n",
      "16 Validation accuracy: 0.9913995\n",
      "epoch: 16, validation loss: 0.034091, best loss: 0.030690, accuracy: 99.14%\n",
      "17 loss:  0.033926804\n",
      "17 Validation accuracy: 0.9913995\n",
      "epoch: 17, validation loss: 0.033927, best loss: 0.030690, accuracy: 99.14%\n",
      "18 loss:  0.048591662\n",
      "18 Validation accuracy: 0.98905396\n",
      "epoch: 18, validation loss: 0.048592, best loss: 0.030690, accuracy: 98.91%\n",
      "19 loss:  0.037393726\n",
      "19 Validation accuracy: 0.99022675\n",
      "epoch: 19, validation loss: 0.037394, best loss: 0.030690, accuracy: 99.02%\n",
      "20 loss:  0.030398598\n",
      "20 Validation accuracy: 0.9917905\n",
      "epoch: 20, validation loss: 0.030399, best loss: 0.030399, accuracy: 99.18%\n",
      "21 loss:  0.029664459\n",
      "21 Validation accuracy: 0.9910086\n",
      "epoch: 21, validation loss: 0.029664, best loss: 0.029664, accuracy: 99.10%\n",
      "22 loss:  0.033004206\n",
      "22 Validation accuracy: 0.9910086\n",
      "epoch: 22, validation loss: 0.033004, best loss: 0.029664, accuracy: 99.10%\n",
      "23 loss:  0.03763596\n",
      "23 Validation accuracy: 0.9898358\n",
      "epoch: 23, validation loss: 0.037636, best loss: 0.029664, accuracy: 98.98%\n",
      "24 loss:  0.034906\n",
      "24 Validation accuracy: 0.9910086\n",
      "epoch: 24, validation loss: 0.034906, best loss: 0.029664, accuracy: 99.10%\n",
      "25 loss:  0.032104235\n",
      "25 Validation accuracy: 0.9910086\n",
      "epoch: 25, validation loss: 0.032104, best loss: 0.029664, accuracy: 99.10%\n",
      "26 loss:  0.034324806\n",
      "26 Validation accuracy: 0.9921814\n",
      "epoch: 26, validation loss: 0.034325, best loss: 0.029664, accuracy: 99.22%\n",
      "27 loss:  0.034934122\n",
      "27 Validation accuracy: 0.9921814\n",
      "epoch: 27, validation loss: 0.034934, best loss: 0.029664, accuracy: 99.22%\n",
      "28 loss:  0.038590916\n",
      "28 Validation accuracy: 0.99022675\n",
      "epoch: 28, validation loss: 0.038591, best loss: 0.029664, accuracy: 99.02%\n",
      "29 loss:  0.041777793\n",
      "29 Validation accuracy: 0.9910086\n",
      "epoch: 29, validation loss: 0.041778, best loss: 0.029664, accuracy: 99.10%\n",
      "30 loss:  0.056659237\n",
      "30 Validation accuracy: 0.988663\n",
      "epoch: 30, validation loss: 0.056659, best loss: 0.029664, accuracy: 98.87%\n",
      "31 loss:  0.043744773\n",
      "31 Validation accuracy: 0.9913995\n",
      "epoch: 31, validation loss: 0.043745, best loss: 0.029664, accuracy: 99.14%\n",
      "32 loss:  0.043829292\n",
      "32 Validation accuracy: 0.98944485\n",
      "epoch: 32, validation loss: 0.043829, best loss: 0.029664, accuracy: 98.94%\n",
      "33 loss:  0.04461792\n",
      "33 Validation accuracy: 0.99022675\n",
      "epoch: 33, validation loss: 0.044618, best loss: 0.029664, accuracy: 99.02%\n",
      "34 loss:  0.037832446\n",
      "34 Validation accuracy: 0.9906177\n",
      "epoch: 34, validation loss: 0.037832, best loss: 0.029664, accuracy: 99.06%\n",
      "35 loss:  0.04152634\n",
      "35 Validation accuracy: 0.9898358\n",
      "epoch: 35, validation loss: 0.041526, best loss: 0.029664, accuracy: 98.98%\n",
      "36 loss:  0.04058332\n",
      "36 Validation accuracy: 0.9906177\n",
      "epoch: 36, validation loss: 0.040583, best loss: 0.029664, accuracy: 99.06%\n",
      "37 loss:  0.04545945\n",
      "37 Validation accuracy: 0.99022675\n",
      "epoch: 37, validation loss: 0.045459, best loss: 0.029664, accuracy: 99.02%\n",
      "38 loss:  0.03792466\n",
      "38 Validation accuracy: 0.9917905\n",
      "epoch: 38, validation loss: 0.037925, best loss: 0.029664, accuracy: 99.18%\n",
      "39 loss:  0.031793226\n",
      "39 Validation accuracy: 0.99296325\n",
      "epoch: 39, validation loss: 0.031793, best loss: 0.029664, accuracy: 99.30%\n",
      "40 loss:  0.030517077\n",
      "40 Validation accuracy: 0.9925723\n",
      "epoch: 40, validation loss: 0.030517, best loss: 0.029664, accuracy: 99.26%\n",
      "41 loss:  0.03585222\n",
      "41 Validation accuracy: 0.9906177\n",
      "epoch: 41, validation loss: 0.035852, best loss: 0.029664, accuracy: 99.06%\n",
      "42 loss:  0.02906615\n",
      "42 Validation accuracy: 0.9933542\n",
      "epoch: 42, validation loss: 0.029066, best loss: 0.029066, accuracy: 99.34%\n",
      "43 loss:  0.04694942\n",
      "43 Validation accuracy: 0.9898358\n",
      "epoch: 43, validation loss: 0.046949, best loss: 0.029066, accuracy: 98.98%\n",
      "44 loss:  0.037104286\n",
      "44 Validation accuracy: 0.9925723\n",
      "epoch: 44, validation loss: 0.037104, best loss: 0.029066, accuracy: 99.26%\n",
      "45 loss:  0.037180677\n",
      "45 Validation accuracy: 0.9917905\n",
      "epoch: 45, validation loss: 0.037181, best loss: 0.029066, accuracy: 99.18%\n",
      "46 loss:  0.033192817\n",
      "46 Validation accuracy: 0.9910086\n",
      "epoch: 46, validation loss: 0.033193, best loss: 0.029066, accuracy: 99.10%\n",
      "47 loss:  0.04179464\n",
      "47 Validation accuracy: 0.9913995\n",
      "epoch: 47, validation loss: 0.041795, best loss: 0.029066, accuracy: 99.14%\n",
      "48 loss:  0.026874244\n",
      "48 Validation accuracy: 0.99296325\n",
      "epoch: 48, validation loss: 0.026874, best loss: 0.026874, accuracy: 99.30%\n",
      "49 loss:  0.03772792\n",
      "49 Validation accuracy: 0.9921814\n",
      "epoch: 49, validation loss: 0.037728, best loss: 0.026874, accuracy: 99.22%\n",
      "50 loss:  0.049497824\n",
      "50 Validation accuracy: 0.99022675\n",
      "epoch: 50, validation loss: 0.049498, best loss: 0.026874, accuracy: 99.02%\n",
      "51 loss:  0.03770093\n",
      "51 Validation accuracy: 0.99413604\n",
      "epoch: 51, validation loss: 0.037701, best loss: 0.026874, accuracy: 99.41%\n",
      "52 loss:  0.043915205\n",
      "52 Validation accuracy: 0.9910086\n",
      "epoch: 52, validation loss: 0.043915, best loss: 0.026874, accuracy: 99.10%\n",
      "53 loss:  0.038376708\n",
      "53 Validation accuracy: 0.9913995\n",
      "epoch: 53, validation loss: 0.038377, best loss: 0.026874, accuracy: 99.14%\n",
      "54 loss:  0.031588778\n",
      "54 Validation accuracy: 0.9925723\n",
      "epoch: 54, validation loss: 0.031589, best loss: 0.026874, accuracy: 99.26%\n",
      "55 loss:  0.057004455\n",
      "55 Validation accuracy: 0.9878812\n",
      "epoch: 55, validation loss: 0.057004, best loss: 0.026874, accuracy: 98.79%\n",
      "56 loss:  0.03660322\n",
      "56 Validation accuracy: 0.99296325\n",
      "epoch: 56, validation loss: 0.036603, best loss: 0.026874, accuracy: 99.30%\n",
      "57 loss:  0.048317574\n",
      "57 Validation accuracy: 0.99022675\n",
      "epoch: 57, validation loss: 0.048318, best loss: 0.026874, accuracy: 99.02%\n",
      "58 loss:  0.043203317\n",
      "58 Validation accuracy: 0.99296325\n",
      "epoch: 58, validation loss: 0.043203, best loss: 0.026874, accuracy: 99.30%\n",
      "59 loss:  0.03789303\n",
      "59 Validation accuracy: 0.9925723\n",
      "epoch: 59, validation loss: 0.037893, best loss: 0.026874, accuracy: 99.26%\n",
      "60 loss:  0.031171672\n",
      "60 Validation accuracy: 0.9937451\n",
      "epoch: 60, validation loss: 0.031172, best loss: 0.026874, accuracy: 99.37%\n",
      "61 loss:  0.03627377\n",
      "61 Validation accuracy: 0.9937451\n",
      "epoch: 61, validation loss: 0.036274, best loss: 0.026874, accuracy: 99.37%\n",
      "62 loss:  0.030938078\n",
      "62 Validation accuracy: 0.9937451\n",
      "epoch: 62, validation loss: 0.030938, best loss: 0.026874, accuracy: 99.37%\n",
      "63 loss:  0.040672753\n",
      "63 Validation accuracy: 0.9921814\n",
      "epoch: 63, validation loss: 0.040673, best loss: 0.026874, accuracy: 99.22%\n",
      "64 loss:  0.036351725\n",
      "64 Validation accuracy: 0.9913995\n",
      "epoch: 64, validation loss: 0.036352, best loss: 0.026874, accuracy: 99.14%\n",
      "65 loss:  0.05279775\n",
      "65 Validation accuracy: 0.99022675\n",
      "epoch: 65, validation loss: 0.052798, best loss: 0.026874, accuracy: 99.02%\n",
      "66 loss:  0.03951089\n",
      "66 Validation accuracy: 0.9913995\n",
      "epoch: 66, validation loss: 0.039511, best loss: 0.026874, accuracy: 99.14%\n",
      "67 loss:  0.042426538\n",
      "67 Validation accuracy: 0.9910086\n",
      "epoch: 67, validation loss: 0.042427, best loss: 0.026874, accuracy: 99.10%\n",
      "68 loss:  0.027628653\n",
      "68 Validation accuracy: 0.99296325\n",
      "epoch: 68, validation loss: 0.027629, best loss: 0.026874, accuracy: 99.30%\n",
      "69 loss:  0.0464794\n",
      "69 Validation accuracy: 0.9921814\n",
      "Early stopping! \n",
      "INFO:tensorflow:Restoring parameters from ./chpt11/model/ex8_4.ckpt\n",
      "Final test accuracy: 99.42%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "n_epochs_before_stop = 20\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "best_loss = np.infty\n",
    "\n",
    "\n",
    "# 定义一个从训练集中随机挑选50个实例的方法\n",
    "def batch_generator(X, y, size):\n",
    "    rnd_idx = np.random.permutation(len(X)) # len(X)是矩阵X的第0维的长度, 生成0..len(X)的随机数\n",
    "    n_batches = len(X) // batch_size # //是整除, mod\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch # yield定义了生成器generator, 可以用next(generator)来调用, 也可以用for循环调用\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    n_epochs_after_best = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in batch_generator(X_train_04, y_train_04, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        \n",
    "        the_loss, acc_valid = sess.run([loss, accuracy], feed_dict={X: X_valid_04, y: y_valid_04, training: True})\n",
    "        print(epoch, \"loss: \", the_loss)\n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)\n",
    "        \n",
    "        if the_loss < best_loss:\n",
    "            best_loss = the_loss\n",
    "            n_epochs_after_best = 0\n",
    "            save_path = saver.save(sess, \"./chpt11/model/ex8_4.ckpt\")\n",
    "        else:\n",
    "            n_epochs_after_best += 1\n",
    "            if n_epochs_after_best > n_epochs_before_stop:\n",
    "                print(\"Early stopping! \")\n",
    "                break\n",
    "        print(\"epoch: {}, validation loss: {:.6f}, best loss: {:.6f}, accuracy: {:.2f}%\".format(\n",
    "            epoch, the_loss, best_loss, acc_valid * 100))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./chpt11/model/ex8_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test_04, y: y_test_04, training: True})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否过拟合训练数据?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./chpt11/model/ex8_4.ckpt\n",
      "accuracy on traning set: 99.97%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./chpt11/model/ex8_4.ckpt\")\n",
    "    acc_train = accuracy.eval(feed_dict={X: X_train_04, y: y_train_04, training: True})\n",
    "    print(\"accuracy on traning set: {:.2f}%\".format(acc_train * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5 使用dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-2afe8e59a606>:19: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4603325c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4603325c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4603325c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4603325c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4569ebc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4569ebc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4569ebc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4569ebc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4569ebc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4569ebc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4569ebc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4569ebc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4569ebc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4569ebc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4569ebc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4569ebc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678bfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678bfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45678bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45678bfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45678bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa45678bfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa45678bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa45678bfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa45678bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa45678bfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa446ac4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa446ac4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa446ac4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa446ac4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa446ac4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa446ac4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa446ac4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa446ac4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa446ac4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa446ac4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa446ac4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa446ac4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4578e0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4578e0748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4578e0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa4578e0748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578e0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578e0748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578e0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa4578e0748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4578e0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4578e0748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4578e0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fa4578e0748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456967550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456967550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456967550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa456967550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa456967550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa456967550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa456967550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fa456967550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa45678f7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 28*28\n",
    "n_outputs = 5\n",
    "n_hidden_neurons = 100\n",
    "n_hidden_layers = 5\n",
    "\n",
    "reset_tf_graph()\n",
    "\n",
    "# 定义输入参数\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder(tf.bool, name=\"training\")\n",
    "\n",
    "# 定义层\n",
    "he_init = tf.initializers.variance_scaling()\n",
    "\n",
    "def make_dnn(inputs):\n",
    "    with tf.name_scope(\"dnn\") as scope:\n",
    "        for n in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dropout(inputs, rate=0.5, training=training)\n",
    "            inputs = tf.layers.dense(inputs, n_hidden_neurons, \n",
    "                                     kernel_initializer=he_init,\n",
    "                                     name=\"hidden%d\" % (n + 1))\n",
    "            # 添加批量标准化\n",
    "            inputs = tf.nn.elu(tf.layers.batch_normalization(inputs, training=training, momentum=0.9))\n",
    "        return inputs\n",
    "\n",
    "dnn_outputs = make_dnn(X)\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, \n",
    "                         kernel_initializer=he_init,\n",
    "                        name=\"logits\")\n",
    "y_probs = tf.nn.softmax(logits, name=\"y_probs\")\n",
    "\n",
    "# 定义交叉熵损失函数\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "# 定义训练操作\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  0.24036534\n",
      "0 Validation accuracy: 0.92220485\n",
      "epoch: 0, validation loss: 0.240365, best loss: 0.240365, accuracy: 92.22%\n",
      "1 loss:  0.20599365\n",
      "1 Validation accuracy: 0.94018763\n",
      "epoch: 1, validation loss: 0.205994, best loss: 0.205994, accuracy: 94.02%\n",
      "2 loss:  0.19890217\n",
      "2 Validation accuracy: 0.94018763\n",
      "epoch: 2, validation loss: 0.198902, best loss: 0.198902, accuracy: 94.02%\n",
      "3 loss:  0.20680825\n",
      "3 Validation accuracy: 0.94175136\n",
      "epoch: 3, validation loss: 0.206808, best loss: 0.198902, accuracy: 94.18%\n",
      "4 loss:  0.16963334\n",
      "4 Validation accuracy: 0.94448787\n",
      "epoch: 4, validation loss: 0.169633, best loss: 0.169633, accuracy: 94.45%\n",
      "5 loss:  0.15191074\n",
      "5 Validation accuracy: 0.9499609\n",
      "epoch: 5, validation loss: 0.151911, best loss: 0.151911, accuracy: 95.00%\n",
      "6 loss:  0.16261908\n",
      "6 Validation accuracy: 0.95191556\n",
      "epoch: 6, validation loss: 0.162619, best loss: 0.151911, accuracy: 95.19%\n",
      "7 loss:  0.15870453\n",
      "7 Validation accuracy: 0.9534793\n",
      "epoch: 7, validation loss: 0.158705, best loss: 0.151911, accuracy: 95.35%\n",
      "8 loss:  0.13381648\n",
      "8 Validation accuracy: 0.96247065\n",
      "epoch: 8, validation loss: 0.133816, best loss: 0.133816, accuracy: 96.25%\n",
      "9 loss:  0.12355682\n",
      "9 Validation accuracy: 0.9628616\n",
      "epoch: 9, validation loss: 0.123557, best loss: 0.123557, accuracy: 96.29%\n",
      "10 loss:  0.13351557\n",
      "10 Validation accuracy: 0.9636435\n",
      "epoch: 10, validation loss: 0.133516, best loss: 0.123557, accuracy: 96.36%\n",
      "11 loss:  0.13369437\n",
      "11 Validation accuracy: 0.96325254\n",
      "epoch: 11, validation loss: 0.133694, best loss: 0.123557, accuracy: 96.33%\n",
      "12 loss:  0.1249621\n",
      "12 Validation accuracy: 0.960907\n",
      "epoch: 12, validation loss: 0.124962, best loss: 0.123557, accuracy: 96.09%\n",
      "13 loss:  0.12432004\n",
      "13 Validation accuracy: 0.9636435\n",
      "epoch: 13, validation loss: 0.124320, best loss: 0.123557, accuracy: 96.36%\n",
      "14 loss:  0.13543746\n",
      "14 Validation accuracy: 0.960907\n",
      "epoch: 14, validation loss: 0.135437, best loss: 0.123557, accuracy: 96.09%\n",
      "15 loss:  0.119671285\n",
      "15 Validation accuracy: 0.9636435\n",
      "epoch: 15, validation loss: 0.119671, best loss: 0.119671, accuracy: 96.36%\n",
      "16 loss:  0.11813018\n",
      "16 Validation accuracy: 0.96716183\n",
      "epoch: 16, validation loss: 0.118130, best loss: 0.118130, accuracy: 96.72%\n",
      "17 loss:  0.103587806\n",
      "17 Validation accuracy: 0.9702893\n",
      "epoch: 17, validation loss: 0.103588, best loss: 0.103588, accuracy: 97.03%\n",
      "18 loss:  0.120304875\n",
      "18 Validation accuracy: 0.9648163\n",
      "epoch: 18, validation loss: 0.120305, best loss: 0.103588, accuracy: 96.48%\n",
      "19 loss:  0.104253\n",
      "19 Validation accuracy: 0.96872556\n",
      "epoch: 19, validation loss: 0.104253, best loss: 0.103588, accuracy: 96.87%\n",
      "20 loss:  0.11341848\n",
      "20 Validation accuracy: 0.96716183\n",
      "epoch: 20, validation loss: 0.113418, best loss: 0.103588, accuracy: 96.72%\n",
      "21 loss:  0.10647079\n",
      "21 Validation accuracy: 0.96950746\n",
      "epoch: 21, validation loss: 0.106471, best loss: 0.103588, accuracy: 96.95%\n",
      "22 loss:  0.10825728\n",
      "22 Validation accuracy: 0.9640344\n",
      "epoch: 22, validation loss: 0.108257, best loss: 0.103588, accuracy: 96.40%\n",
      "23 loss:  0.11256762\n",
      "23 Validation accuracy: 0.96716183\n",
      "epoch: 23, validation loss: 0.112568, best loss: 0.103588, accuracy: 96.72%\n",
      "24 loss:  0.12341041\n",
      "24 Validation accuracy: 0.96247065\n",
      "epoch: 24, validation loss: 0.123410, best loss: 0.103588, accuracy: 96.25%\n",
      "25 loss:  0.14532389\n",
      "25 Validation accuracy: 0.9534793\n",
      "epoch: 25, validation loss: 0.145324, best loss: 0.103588, accuracy: 95.35%\n",
      "26 loss:  0.1350525\n",
      "26 Validation accuracy: 0.9601251\n",
      "epoch: 26, validation loss: 0.135053, best loss: 0.103588, accuracy: 96.01%\n",
      "27 loss:  0.09377958\n",
      "27 Validation accuracy: 0.9741986\n",
      "epoch: 27, validation loss: 0.093780, best loss: 0.093780, accuracy: 97.42%\n",
      "28 loss:  0.11601067\n",
      "28 Validation accuracy: 0.9691165\n",
      "epoch: 28, validation loss: 0.116011, best loss: 0.093780, accuracy: 96.91%\n",
      "29 loss:  0.09668521\n",
      "29 Validation accuracy: 0.9702893\n",
      "epoch: 29, validation loss: 0.096685, best loss: 0.093780, accuracy: 97.03%\n",
      "30 loss:  0.10323109\n",
      "30 Validation accuracy: 0.97068024\n",
      "epoch: 30, validation loss: 0.103231, best loss: 0.093780, accuracy: 97.07%\n",
      "31 loss:  0.103337206\n",
      "31 Validation accuracy: 0.96716183\n",
      "epoch: 31, validation loss: 0.103337, best loss: 0.093780, accuracy: 96.72%\n",
      "32 loss:  0.106260486\n",
      "32 Validation accuracy: 0.9691165\n",
      "epoch: 32, validation loss: 0.106260, best loss: 0.093780, accuracy: 96.91%\n",
      "33 loss:  0.09691043\n",
      "33 Validation accuracy: 0.971853\n",
      "epoch: 33, validation loss: 0.096910, best loss: 0.093780, accuracy: 97.19%\n",
      "34 loss:  0.10191897\n",
      "34 Validation accuracy: 0.96989834\n",
      "epoch: 34, validation loss: 0.101919, best loss: 0.093780, accuracy: 96.99%\n",
      "35 loss:  0.10150776\n",
      "35 Validation accuracy: 0.97537136\n",
      "epoch: 35, validation loss: 0.101508, best loss: 0.093780, accuracy: 97.54%\n",
      "36 loss:  0.105623245\n",
      "36 Validation accuracy: 0.96950746\n",
      "epoch: 36, validation loss: 0.105623, best loss: 0.093780, accuracy: 96.95%\n",
      "37 loss:  0.10573904\n",
      "37 Validation accuracy: 0.9714621\n",
      "epoch: 37, validation loss: 0.105739, best loss: 0.093780, accuracy: 97.15%\n",
      "38 loss:  0.10609841\n",
      "38 Validation accuracy: 0.96872556\n",
      "epoch: 38, validation loss: 0.106098, best loss: 0.093780, accuracy: 96.87%\n",
      "39 loss:  0.08428252\n",
      "39 Validation accuracy: 0.9749805\n",
      "epoch: 39, validation loss: 0.084283, best loss: 0.084283, accuracy: 97.50%\n",
      "40 loss:  0.1117527\n",
      "40 Validation accuracy: 0.96716183\n",
      "epoch: 40, validation loss: 0.111753, best loss: 0.084283, accuracy: 96.72%\n",
      "41 loss:  0.1146879\n",
      "41 Validation accuracy: 0.96247065\n",
      "epoch: 41, validation loss: 0.114688, best loss: 0.084283, accuracy: 96.25%\n",
      "42 loss:  0.10482772\n",
      "42 Validation accuracy: 0.96872556\n",
      "epoch: 42, validation loss: 0.104828, best loss: 0.084283, accuracy: 96.87%\n",
      "43 loss:  0.09291918\n",
      "43 Validation accuracy: 0.9741986\n",
      "epoch: 43, validation loss: 0.092919, best loss: 0.084283, accuracy: 97.42%\n",
      "44 loss:  0.09069742\n",
      "44 Validation accuracy: 0.9710711\n",
      "epoch: 44, validation loss: 0.090697, best loss: 0.084283, accuracy: 97.11%\n",
      "45 loss:  0.099029124\n",
      "45 Validation accuracy: 0.9714621\n",
      "epoch: 45, validation loss: 0.099029, best loss: 0.084283, accuracy: 97.15%\n",
      "46 loss:  0.10297256\n",
      "46 Validation accuracy: 0.9702893\n",
      "epoch: 46, validation loss: 0.102973, best loss: 0.084283, accuracy: 97.03%\n",
      "47 loss:  0.09771806\n",
      "47 Validation accuracy: 0.971853\n",
      "epoch: 47, validation loss: 0.097718, best loss: 0.084283, accuracy: 97.19%\n",
      "48 loss:  0.11487993\n",
      "48 Validation accuracy: 0.96872556\n",
      "epoch: 48, validation loss: 0.114880, best loss: 0.084283, accuracy: 96.87%\n",
      "49 loss:  0.10294957\n",
      "49 Validation accuracy: 0.97341675\n",
      "epoch: 49, validation loss: 0.102950, best loss: 0.084283, accuracy: 97.34%\n",
      "50 loss:  0.09715631\n",
      "50 Validation accuracy: 0.9714621\n",
      "epoch: 50, validation loss: 0.097156, best loss: 0.084283, accuracy: 97.15%\n",
      "51 loss:  0.10107735\n",
      "51 Validation accuracy: 0.971853\n",
      "epoch: 51, validation loss: 0.101077, best loss: 0.084283, accuracy: 97.19%\n",
      "52 loss:  0.09912812\n",
      "52 Validation accuracy: 0.96872556\n",
      "epoch: 52, validation loss: 0.099128, best loss: 0.084283, accuracy: 96.87%\n",
      "53 loss:  0.08426802\n",
      "53 Validation accuracy: 0.9765442\n",
      "epoch: 53, validation loss: 0.084268, best loss: 0.084268, accuracy: 97.65%\n",
      "54 loss:  0.10083084\n",
      "54 Validation accuracy: 0.9667709\n",
      "epoch: 54, validation loss: 0.100831, best loss: 0.084268, accuracy: 96.68%\n",
      "55 loss:  0.12204872\n",
      "55 Validation accuracy: 0.9652072\n",
      "epoch: 55, validation loss: 0.122049, best loss: 0.084268, accuracy: 96.52%\n",
      "56 loss:  0.1011844\n",
      "56 Validation accuracy: 0.97263485\n",
      "epoch: 56, validation loss: 0.101184, best loss: 0.084268, accuracy: 97.26%\n",
      "57 loss:  0.10806479\n",
      "57 Validation accuracy: 0.96716183\n",
      "epoch: 57, validation loss: 0.108065, best loss: 0.084268, accuracy: 96.72%\n",
      "58 loss:  0.10282577\n",
      "58 Validation accuracy: 0.97341675\n",
      "epoch: 58, validation loss: 0.102826, best loss: 0.084268, accuracy: 97.34%\n",
      "59 loss:  0.109987855\n",
      "59 Validation accuracy: 0.97068024\n",
      "epoch: 59, validation loss: 0.109988, best loss: 0.084268, accuracy: 97.07%\n",
      "60 loss:  0.088428244\n",
      "60 Validation accuracy: 0.97341675\n",
      "epoch: 60, validation loss: 0.088428, best loss: 0.084268, accuracy: 97.34%\n",
      "61 loss:  0.09162501\n",
      "61 Validation accuracy: 0.9745895\n",
      "epoch: 61, validation loss: 0.091625, best loss: 0.084268, accuracy: 97.46%\n",
      "62 loss:  0.08958398\n",
      "62 Validation accuracy: 0.9730258\n",
      "epoch: 62, validation loss: 0.089584, best loss: 0.084268, accuracy: 97.30%\n",
      "63 loss:  0.091584824\n",
      "63 Validation accuracy: 0.9741986\n",
      "epoch: 63, validation loss: 0.091585, best loss: 0.084268, accuracy: 97.42%\n",
      "64 loss:  0.084705114\n",
      "64 Validation accuracy: 0.9730258\n",
      "epoch: 64, validation loss: 0.084705, best loss: 0.084268, accuracy: 97.30%\n",
      "65 loss:  0.09109559\n",
      "65 Validation accuracy: 0.97341675\n",
      "epoch: 65, validation loss: 0.091096, best loss: 0.084268, accuracy: 97.34%\n",
      "66 loss:  0.08562691\n",
      "66 Validation accuracy: 0.97537136\n",
      "epoch: 66, validation loss: 0.085627, best loss: 0.084268, accuracy: 97.54%\n",
      "67 loss:  0.09182269\n",
      "67 Validation accuracy: 0.971853\n",
      "epoch: 67, validation loss: 0.091823, best loss: 0.084268, accuracy: 97.19%\n",
      "68 loss:  0.0871855\n",
      "68 Validation accuracy: 0.9730258\n",
      "epoch: 68, validation loss: 0.087186, best loss: 0.084268, accuracy: 97.30%\n",
      "69 loss:  0.092098854\n",
      "69 Validation accuracy: 0.97380763\n",
      "epoch: 69, validation loss: 0.092099, best loss: 0.084268, accuracy: 97.38%\n",
      "70 loss:  0.09125716\n",
      "70 Validation accuracy: 0.9741986\n",
      "epoch: 70, validation loss: 0.091257, best loss: 0.084268, accuracy: 97.42%\n",
      "71 loss:  0.10097068\n",
      "71 Validation accuracy: 0.9714621\n",
      "epoch: 71, validation loss: 0.100971, best loss: 0.084268, accuracy: 97.15%\n",
      "72 loss:  0.09496061\n",
      "72 Validation accuracy: 0.97380763\n",
      "epoch: 72, validation loss: 0.094961, best loss: 0.084268, accuracy: 97.38%\n",
      "73 loss:  0.09116392\n",
      "73 Validation accuracy: 0.9745895\n",
      "epoch: 73, validation loss: 0.091164, best loss: 0.084268, accuracy: 97.46%\n",
      "74 loss:  0.09346692\n",
      "74 Validation accuracy: 0.971853\n",
      "Early stopping! \n",
      "INFO:tensorflow:Restoring parameters from ./chpt11/model/ex8_5.ckpt\n",
      "Final test accuracy: 97.47%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "n_epochs_before_stop = 20\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "best_loss = np.infty\n",
    "\n",
    "\n",
    "# 定义一个从训练集中随机挑选50个实例的方法\n",
    "def batch_generator(X, y, size):\n",
    "    rnd_idx = np.random.permutation(len(X)) # len(X)是矩阵X的第0维的长度, 生成0..len(X)的随机数\n",
    "    n_batches = len(X) // batch_size # //是整除, mod\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch # yield定义了生成器generator, 可以用next(generator)来调用, 也可以用for循环调用\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    n_epochs_after_best = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in batch_generator(X_train_04, y_train_04, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        \n",
    "        the_loss, acc_valid = sess.run([loss, accuracy], feed_dict={X: X_valid_04, y: y_valid_04, training: True})\n",
    "        print(epoch, \"loss: \", the_loss)\n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)\n",
    "        \n",
    "        if the_loss < best_loss:\n",
    "            best_loss = the_loss\n",
    "            n_epochs_after_best = 0\n",
    "            save_path = saver.save(sess, \"./chpt11/model/ex8_5.ckpt\")\n",
    "        else:\n",
    "            n_epochs_after_best += 1\n",
    "            if n_epochs_after_best > n_epochs_before_stop:\n",
    "                print(\"Early stopping! \")\n",
    "                break\n",
    "        print(\"epoch: {}, validation loss: {:.6f}, best loss: {:.6f}, accuracy: {:.2f}%\".format(\n",
    "            epoch, the_loss, best_loss, acc_valid * 100))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./chpt11/model/ex8_5.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test_04, y: y_test_04, training: True})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-gpu",
   "language": "python",
   "name": "dev-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
