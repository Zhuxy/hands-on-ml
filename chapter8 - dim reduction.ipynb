{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是PCA里的可解释方差\n",
    "\n",
    "参考 https://ro-che.info/articles/2017-12-11-pca-explained-variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备一组数据, 横列为样本数, 纵列为变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42298398,  1.7352837 ,  0.411915  ],\n",
       "       [-1.54987816, -0.2647112 , -0.6524724 ],\n",
       "       [-0.06442932,  2.0994707 ,  0.7603068 ],\n",
       "       [ 0.27088135,  0.8633512 ,  0.1551048 ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[-0.42298398,  1.7352837,  0.4119150],\n",
    "[-1.54987816, -0.2647112, -0.6524724],\n",
    "[-0.06442932,  2.0994707,  0.7603068],\n",
    "[ 0.27088135,  0.8633512,  0.1551048]])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个变量的样本偏差:  [0.62617148 1.10689586 0.36122036]\n",
      "样本总方差:  2.0942876968141357\n",
      "变量的可解释方差:  [0.29899019 0.52853095 0.17247886]\n"
     ]
    }
   ],
   "source": [
    "# 在0轴纵列上计算每个变量的方差\n",
    "\n",
    "sample_vars = np.var(a, axis=0, ddof=1) # numpy里的var默认是均方差, 除以 N - ddof(=0), 方差是除以N-1, 所以设ddof为1\n",
    "\n",
    "print(\"每个变量的样本偏差: \", sample_vars)\n",
    "\n",
    "# 样本方差之和是total variance, 总方差\n",
    "total_var = np.sum(sample_vars)\n",
    "print(\"样本总方差: \", total_var)\n",
    "\n",
    "# 每个样本方差除以总方差既为每个变量的可解释方差\n",
    "explained_vars = sample_vars/total_var\n",
    "print(\"变量的可解释方差: \", explained_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试下sklearn里的PCA计算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方差解释率:  [0.88235567 0.11674697 0.00089736]\n",
      "转换后的样本变量方差:  [1.84790662 0.24450174 0.00187933]\n",
      "转换后的总方差:  2.0942876968141375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA() # 不降维的情况下计算PCA\n",
    "\n",
    "b = pca.fit_transform(a)\n",
    "print(\"方差解释率: \", pca.explained_variance_ratio_) # 前2个主成分占了99%的总方差\n",
    "\n",
    "\n",
    "b_vars = np.var(b, axis=0, ddof=1)\n",
    "print(\"转换后的样本变量方差: \", b_vars)\n",
    "\n",
    "b_vars = np.sum(b_vars) # 转换后的总方差和原来一致\n",
    "print(\"转换后的总方差: \", b_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核PCA Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 准备瑞士卷数据集\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)\n",
    "y = t > 6.9\n",
    "print(\"X shape: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用随机网格搜索寻找逻辑回归问题下的最佳核PCA超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"kpca\", KernelPCA(n_components=2)),\n",
    "    (\"log_req\", LogisticRegression(solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "param_grid = [{\n",
    "    \"kpca__kernel\": [\"rbf\", \"sigmoid\"], \n",
    "    # kpca__kernel 里的kpca对应pipeline里的kpca,意思是找pipeline里名字为kpca的transformer的kernel参数\n",
    "    \"kpca__gamma\": np.linspace(0.03, 0.05, 10)\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>使用交叉验证的方格搜索来寻找可以最小化重建前图像误差的核方法和超参数</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLE局部线性嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
    "\n",
    "X_reduced = lle.fit_transform(X)\n",
    "\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题9\n",
    "\n",
    "加载 MNIST 数据集(在第 3 章中介绍),并将其分成一个训练集和一个测试集(将前60,000 个实例用于训练,其余 10,000 个用于测试)。在数据集上训练一个随机森林分类器,并记录了花费多长时间,然后在测试集上评估模型。接下来,使用 PCA 降低数据集的维度,设置方差解释率为 95%。在降维后的数据集上训练一个新的随机森林分类器,并查看需要多长时间。训练速度更快?接下来评估测试集上的分类器:它与以前的分类器比较起来如何?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 引入MNIST数据集\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\", data_home=\"./datasets\")\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# 准备训练集和测试集\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000].astype(\"int\"), y[60000:].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/living/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 s ± 41.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "random forest score:  0.9492\n"
     ]
    }
   ],
   "source": [
    "# 训练随机森林分类器\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "%timeit rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"random forest score: \", rnd_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/living/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25 s ± 34.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "reduced random forest score:  0.9009\n"
     ]
    }
   ],
   "source": [
    "# 使用PCA降维\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "reduced_rnd_clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "%timeit reduced_rnd_clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "print(\"reduced random forest score: \", reduced_rnd_clf.score(X_test_reduced, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
